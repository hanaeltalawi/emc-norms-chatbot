'''
1. Install Python dependencies
    pip install -r requirements.txt

2. Install Ollama (separately)
    # On macOS/Linux:
    curl -fsSL https://ollama.ai/install.sh | sh

    # On Windows: Download from https://ollama.ai/

3. Start Ollama service
    ollama serve

4. Pull required models (in separate terminal)
    ollama pull llama3.1:8b
    ollama pull phi3:latest  
    ollama pull phi:latest
    ollama pull mistral:7b
    ollama pull tinyllama:latest

5. Run the app
    python -m streamlit run app.py
'''

# Web App framework
streamlit>=1.38.0

# AI Framework Core Components
langchain>=0.3.0
langchain-community>=0.3.0
langchain-chroma>=0.1.2               
langchain-core>=0.3.0
langchain-huggingface>=0.1.0

# Document Processing
python-docx>=1.1.2

# Search & Retrieval
rank-bm25>=0.2.2

# Models & Embeddings
sentence-transformers>=3.0.1
torch>=2.4.0    # For CPU
# For GPU support (CUDA 12.1 example): torch==2.4.0+cu121 --index-url https://download.pytorch.org/whl/cu121

# Math & Data Processing
numpy>=1.26.0
pandas>=2.2.0

# Vector database
chromadb>=0.5.5

# Model Hub
huggingface-hub>=0.23.0

# Utilities
pypika>=0.48.9
typing-extensions>=4.12.0
requests>=2.32.0
urllib3>=2.2.2